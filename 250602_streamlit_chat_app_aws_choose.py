import streamlit as st
import os
import json
from langchain_aws import ChatBedrock # Bedrockç”¨
from langchain.memory import ConversationBufferMemory
from langchain_community.tools import DuckDuckGoSearchResults
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from botocore.exceptions import NoCredentialsError, ClientError, ProfileNotFound

# --- å®šæ•° ---
AVAILABLE_MODELS = {
    "Anthropic Claude 3 Sonnet": "anthropic.claude-3-sonnet-20240229-v1:0",
    "Anthropic Claude 3 Haiku": "anthropic.claude-3-haiku-20240307-v1:0",
    "Anthropic Claude 3 Opus": "anthropic.claude-3-opus-20240229-v1:0", # Opusè¿½åŠ ä¾‹
    "Amazon Titan Text G1 - Express": "amazon.titan-text-express-v1",
    "Meta Llama 3 8B Instruct": "meta.llama3-8b-instruct-v1:0",
    "Cohere Command R": "cohere.command-r-v1:0",
}
DEFAULT_MODEL_DISPLAY_NAME = "Anthropic Claude 3 Sonnet"
DEFAULT_MODEL_API_NAME = AVAILABLE_MODELS[DEFAULT_MODEL_DISPLAY_NAME]
DEFAULT_MAX_TOKENS = 2048
DEFAULT_TEMPERATURE = 0.7
DEFAULT_USE_SEARCH = True
DEFAULT_AWS_REGION = os.getenv("AWS_DEFAULT_REGION", "us-east-1")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– ---
if "selected_model_name" not in st.session_state:
    st.session_state.selected_model_name = DEFAULT_MODEL_API_NAME
if "selected_max_tokens" not in st.session_state:
    st.session_state.selected_max_tokens = DEFAULT_MAX_TOKENS
if "selected_temperature" not in st.session_state:
    st.session_state.selected_temperature = DEFAULT_TEMPERATURE
if "selected_aws_region" not in st.session_state:
    st.session_state.selected_aws_region = DEFAULT_AWS_REGION
if "use_duckduckgo" not in st.session_state:
    st.session_state.use_duckduckgo = DEFAULT_USE_SEARCH

if "messages" not in st.session_state:
    st.session_state.messages = []
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        memory_key="chat_history", return_messages=True
    )
if "search_url_history" not in st.session_state:
    st.session_state.search_url_history = []

# --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•° ---
def on_settings_change():
    if "agent_executor" in st.session_state:
        del st.session_state.agent_executor
    # LLMã‚„Toolsã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢ã—ãŸã„å ´åˆã¯ã€get_llm.clear() ãªã©ã‚‚æ¤œè¨ã™ã‚‹ãŒã€
    # é€šå¸¸ã¯å¼•æ•°ãŒå¤‰ã‚ã‚Œã° @st.cache_resource ãŒå†å®Ÿè¡Œã•ã‚Œã‚‹ã®ã§ä¸è¦ã€‚

# --- LangChainã®ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ– ---
@st.cache_resource
def get_llm(model_id: str, max_tokens_from_ui: int, temperature_from_ui: float, region_name: str):
    try:
        model_kwargs = {}
        if "anthropic.claude" in model_id:
            model_kwargs["max_tokens_to_sample"] = max_tokens_from_ui
            # Claudeã®å ´åˆã€temperatureã¯ChatBedrockã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿å¼•æ•°ã§è¨­å®š
        elif "amazon.titan" in model_id:
            model_kwargs["textGenerationConfig"] = {
                "maxTokenCount": max_tokens_from_ui,
                "temperature": temperature_from_ui, # Titanã¯ã“ã“ã§æ¸©åº¦è¨­å®š
                "stopSequences": [],
                "topP": 1.0,
            }
        elif "meta.llama" in model_id:
            model_kwargs["max_gen_len"] = max_tokens_from_ui
            # Llamaã®å ´åˆã€temperatureã¯ChatBedrockã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿å¼•æ•°ã§è¨­å®š
        elif "cohere.command-r" in model_id:
            model_kwargs["max_tokens"] = max_tokens_from_ui
            # Cohereã®å ´åˆã€temperatureã¯ChatBedrockã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿å¼•æ•°ã§è¨­å®š
        else:
            st.warning(f"ãƒ¢ãƒ‡ãƒ« {model_id} ã®ãŸã‚ã®ç‰¹å®šã® `max_tokens` ã‚­ãƒ¼ãŒä¸æ˜ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’è©¦ã¿ã¾ã™ãŒã€å‹•ä½œã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

        llm = ChatBedrock(
            region_name=region_name,
            model_id=model_id,
            model_kwargs=model_kwargs if model_kwargs else None,
            temperature=temperature_from_ui if "amazon.titan" not in model_id else None,
        )
        return llm

    except (NoCredentialsError, ProfileNotFound):
        st.error("AWSèªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚AWS CLIãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã¾ãŸã¯ã€æœ‰åŠ¹ãªAWSãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    except ClientError as e:
        error_code = e.response.get("Error", {}).get("Code")
        if error_code == "AccessDeniedException" or "AccessDenied" in str(e) :
            st.error(f"Bedrockã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚IAMæ¨©é™ã¨ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„: {e}")
        elif error_code == "ValidationException" and "modelId" in str(e):
            st.error(f"æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ID '{model_id}' ãŒãƒªãƒ¼ã‚¸ãƒ§ãƒ³ '{region_name}' ã§ç„¡åŠ¹ã‹ã€ã‚¢ã‚¯ã‚»ã‚¹æ¨©ãŒã‚ã‚Šã¾ã›ã‚“ã€‚Bedrockã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.error(f"AWS Bedrock APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()
    except Exception as e:
        st.error(f"LLM ({model_id}) ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.stop()

@st.cache_resource
def get_tools(enable_search: bool):
    if enable_search:
        search_tool = DuckDuckGoSearchResults(name="duckduckgo_results_json", max_results=3)
        return [search_tool]
    return []

def get_agent_executor(llm, tools):
    if "agent_executor" not in st.session_state:
        system_message_parts = ["ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"]
        if tools:
            system_message_parts.append("å¿…è¦ã«å¿œã˜ã¦DuckDuckGoã‚’ä½¿ã£ã¦Webæ¤œç´¢ã‚’è¡Œã„ã€æœ€æ–°æƒ…å ±ã‚„ç‰¹å®šã®æƒ…å ±ã‚’èª¿ã¹ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¤œç´¢çµæœã‚’åˆ©ç”¨ã—ãŸå ´åˆã¯ã€ãã®æƒ…å ±æºã«ã¤ã„ã¦è§¦ã‚Œã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚")
        else:
            system_message_parts.append("Webæ¤œç´¢æ©Ÿèƒ½ã¯ç¾åœ¨ã‚ªãƒ•ã«ãªã£ã¦ã„ã¾ã™ã€‚")
        
        system_message_parts.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€çµ‚çš„ãªå›ç­”ã¯ã€ã„ã‹ãªã‚‹å ´åˆã‚‚é€šå¸¸ã®æ–‡ç« ã§ã€äººé–“ãŒèª­ã¿ã‚„ã™ã„å¹³æ˜“ãªãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ã€‚JSONå½¢å¼ã‚„ãã®ä»–ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒè§£é‡ˆã™ã‚‹ã‚ˆã†ãªæ§‹é€ åŒ–ã•ã‚ŒãŸå½¢å¼ã§æœ€çµ‚å›ç­”ã‚’è¿”ã•ãªã„ã§ãã ã•ã„ã€‚")
        final_system_message = " ".join(system_message_parts)

        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", final_system_message),
                MessagesPlaceholder(variable_name="chat_history", optional=True),
                ("user", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ]
        )
        agent = create_tool_calling_agent(llm, tools, prompt)
        st.session_state.agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,  # ã“ã“ã‚’ä¿®æ­£ (True ã¾ãŸã¯ False ã«å›ºå®š)
            handle_parsing_errors=True,
            return_intermediate_steps=True
        )
    return st.session_state.agent_executor

# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIã¨ãƒ­ã‚¸ãƒƒã‚¯ ---
st.set_page_config(page_title="Bedrock Webæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ (è¨­å®šå¯èƒ½)", layout="wide")
st.title("AWS Bedrock Webæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ ğŸŒ (è¨­å®šå¯èƒ½)")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("LLMã¨è¨€èªãƒ¢ãƒ‡ãƒ«è¨­å®š")

    common_aws_regions = [
        "us-east-1", "us-west-2", "ap-northeast-1", "ap-southeast-1", 
        "eu-central-1", "eu-west-1", "eu-west-2", "ap-south-1", 
        "ca-central-1", "sa-east-1" # ã•ã‚‰ã«ãƒªãƒ¼ã‚¸ãƒ§ãƒ³è¿½åŠ 
    ]
    try:
        default_region_index = common_aws_regions.index(st.session_state.selected_aws_region)
    except ValueError: # ä¿å­˜ã•ã‚ŒãŸãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãŒãƒªã‚¹ãƒˆã«ãªã„å ´åˆ
        st.session_state.selected_aws_region = DEFAULT_AWS_REGION # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã™
        try:
            default_region_index = common_aws_regions.index(st.session_state.selected_aws_region)
        except ValueError: # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚‚ãƒªã‚¹ãƒˆã«ãªã„æ¥µç«¯ãªã‚±ãƒ¼ã‚¹
             default_region_index = 0
             st.session_state.selected_aws_region = common_aws_regions[0]


    selected_region_name = st.selectbox(
        "AWS ãƒªãƒ¼ã‚¸ãƒ§ãƒ³:",
        options=common_aws_regions,
        index=default_region_index,
        on_change=on_settings_change,
        key="sb_aws_region"
    )
    st.session_state.selected_aws_region = selected_region_name

    current_model_display_name = DEFAULT_MODEL_DISPLAY_NAME
    for display_name, api_name in AVAILABLE_MODELS.items():
        if api_name == st.session_state.selected_model_name:
            current_model_display_name = display_name
            break
    
    selected_display_name = st.selectbox(
        "LLMãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ:",
        options=list(AVAILABLE_MODELS.keys()),
        index=list(AVAILABLE_MODELS.keys()).index(current_model_display_name),
        on_change=on_settings_change,
        key="sb_model_display_name"
    )
    st.session_state.selected_model_name = AVAILABLE_MODELS[selected_display_name]

    st.session_state.selected_max_tokens = st.number_input(
        "æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°:",
        min_value=256,
        max_value=400000, # Claude 3 Opus ã¯ 200K context, Llama3ã¯8Kãªã©ã€‚ã‹ãªã‚Šå¹…ãŒã‚ã‚‹ã€‚
        value=st.session_state.selected_max_tokens,
        step=128,
        on_change=on_settings_change,
        key="ni_max_tokens"
    )

    st.session_state.selected_temperature = st.slider(
        "Temperature (å‡ºåŠ›ã®å¤šæ§˜æ€§):",
        min_value=0.0,
        max_value=1.0, # Titanãªã©ã¯2.0ã¾ã§ã„ã‘ã‚‹ãŒã€ä¸€èˆ¬çš„ã«ã¯1.0ãŒä¸Šé™
        value=st.session_state.selected_temperature,
        step=0.05,
        on_change=on_settings_change,
        key="slider_temperature"
    )

    st.markdown("---")
    st.header("ãƒ„ãƒ¼ãƒ«è¨­å®š")
    st.session_state.use_duckduckgo = st.toggle(
        "DuckDuckGo Webæ¤œç´¢ã‚’æœ‰åŠ¹ã«ã™ã‚‹",
        value=st.session_state.use_duckduckgo,
        on_change=on_settings_change,
        key="toggle_use_search"
    )

    st.markdown("---")
    st.header("ä¼šè©±æ“ä½œ")
    if st.button("ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_chat"):
        st.session_state.messages = []
        st.session_state.search_url_history = []
        if "agent_executor" in st.session_state:
            del st.session_state.agent_executor
        if "memory" in st.session_state:
            del st.session_state.memory
            st.session_state.memory = ConversationBufferMemory(
                memory_key="chat_history", return_messages=True
            )
        st.rerun()

    st.markdown("---")
    st.subheader("æ¤œç´¢ã•ã‚ŒãŸURLå±¥æ­´")
    if st.session_state.get("search_url_history"):
        for i, url in enumerate(reversed(st.session_state.search_url_history)):
            try:
                domain = url.split('//')[-1].split('/')[0]
            except:
                domain = "ä¸æ˜ãªãƒ‰ãƒ¡ã‚¤ãƒ³"
            st.markdown(f"{len(st.session_state.search_url_history) - i}. [{domain}]({url})")
    else:
        st.caption("ã¾ã æ¤œç´¢ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    st.markdown("---")
    st.subheader("AWSèªè¨¼ã«ã¤ã„ã¦")
    st.caption(
        "ã“ã®ã‚¢ãƒ—ãƒªã¯AWSèªè¨¼æƒ…å ±ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã§èªè¨¼æƒ…å ±ã‚’è¨­å®šã—ã¦ãã ã•ã„:\n"
        "1. ç’°å¢ƒå¤‰æ•° (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN (ã‚ªãƒ—ã‚·ãƒ§ãƒ³), AWS_DEFAULT_REGION)\n"
        "2. AWS CLIã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« (~/.aws/credentials ã¨ ~/.aws/config)\n"
        "3. (EC2/ECS/Lambdaãªã©) IAMãƒ­ãƒ¼ãƒ«"
    )
    st.markdown("[AWSèªè¨¼æƒ…å ±ã®è¨­å®šè©³ç´°](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)")


    st.markdown("---")
    st.subheader("ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
    if st.checkbox("ä¼šè©±ãƒ¡ãƒ¢ãƒªã‚’è¡¨ç¤º (LangChain)"):
        if "memory" in st.session_state and hasattr(st.session_state.memory, 'chat_memory'):
            st.write(st.session_state.memory.chat_memory.messages)
        else:
            st.caption("ãƒ¡ãƒ¢ãƒªã¯ã¾ã åˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„ã‹ã€ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚")

# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
current_llm = get_llm(
    st.session_state.selected_model_name,
    st.session_state.selected_max_tokens,
    st.session_state.selected_temperature,
    st.session_state.selected_aws_region
)
current_tools = get_tools(st.session_state.use_duckduckgo)
agent_executor = get_agent_executor(current_llm, current_tools)

caption_model_display_name = [k for k, v in AVAILABLE_MODELS.items() if v == st.session_state.selected_model_name][0]
st.caption(f"LLM: Bedrock ({caption_model_display_name} in {st.session_state.selected_aws_region}), Search: DuckDuckGo ({'ON' if st.session_state.use_duckduckgo else 'OFF'})")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    st.session_state.messages.append({"role": "user", "content": user_prompt})
    with st.chat_message("user"):
        st.markdown(user_prompt)

    with st.chat_message("assistant"):
        try:
            with st.spinner("AIãŒè€ƒãˆã¦ã„ã¾ã™..."):
                chat_history_messages = st.session_state.memory.chat_memory.messages
                response_data = agent_executor.invoke(
                    {
                        "input": user_prompt,
                        "chat_history": chat_history_messages
                    }
                )
                
                # --- Bedrock Claude 3ãªã©ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ–ãƒ­ãƒƒã‚¯å½¢å¼ã®å¿œç­”ã‚’å‡¦ç† ---
                ai_response_raw = response_data.get('output', "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                final_ai_response = ""

                if isinstance(ai_response_raw, list) and len(ai_response_raw) > 0:
                    text_parts = []
                    all_items_are_valid_text_blocks = True
                    for item in ai_response_raw:
                        if isinstance(item, dict) and item.get('type') == 'text' and 'text' in item:
                            text_parts.append(item['text'])
                        else:
                            all_items_are_valid_text_blocks = False
                            break 
                    if all_items_are_valid_text_blocks and text_parts:
                        final_ai_response = "".join(text_parts)
                    else:
                        # æœŸå¾…ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ–ãƒ­ãƒƒã‚¯å½¢å¼ã§ã¯ãªã„ãƒªã‚¹ãƒˆã®å ´åˆã€æ–‡å­—åˆ—ã¨ã—ã¦çµåˆ
                        st.warning(f"AIã‹ã‚‰ã®å¿œç­”ãŒäºˆæœŸã›ã¬ãƒªã‚¹ãƒˆå½¢å¼ã§ã—ãŸã€‚æ–‡å­—åˆ—ã¨ã—ã¦çµåˆã—ã¾ã™: {ai_response_raw}")
                        final_ai_response = " ".join(map(str, ai_response_raw))
                elif isinstance(ai_response_raw, str):
                    final_ai_response = ai_response_raw
                elif ai_response_raw is None:
                    final_ai_response = "å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                else:
                    st.warning(f"AIã‹ã‚‰ã®å¿œç­”ãŒäºˆæœŸã›ã¬å‹ã§ã—ãŸ: {type(ai_response_raw)}")
                    final_ai_response = str(ai_response_raw)

                ai_response = final_ai_response
                # --- å‡¦ç†ã“ã“ã¾ã§ ---

                intermediate_steps = response_data.get('intermediate_steps', [])

                urls_found_this_turn = []
                if st.session_state.use_duckduckgo:
                    for step in intermediate_steps:
                        action, observation = step
                        if hasattr(action, 'tool') and action.tool == "duckduckgo_results_json":
                            if isinstance(observation, str):
                                try:
                                    results_list = json.loads(observation)
                                    for res_item in results_list:
                                        if isinstance(res_item, dict) and "link" in res_item:
                                            urls_found_this_turn.append(res_item["link"])
                                except json.JSONDecodeError:
                                    st.warning(f"æ¤œç´¢çµæœã®JSONè§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {observation[:200]}...")
                            elif isinstance(observation, list):
                                for res_item in observation:
                                    if isinstance(res_item, dict) and "link" in res_item:
                                        urls_found_this_turn.append(res_item["link"])

                for url in urls_found_this_turn:
                    if url not in st.session_state.search_url_history:
                        st.session_state.search_url_history.append(url)

            st.markdown(ai_response)
            st.session_state.messages.append({"role": "assistant", "content": ai_response})
            st.session_state.memory.chat_memory.add_user_message(user_prompt)
            st.session_state.memory.chat_memory.add_ai_message(ai_response)

        except Exception as e:
            error_message = f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            st.error(error_message)
            st.session_state.messages.append({"role": "assistant", "content": error_message})