import streamlit as st
import os
import re
# langchain_google_genaiã¯ä¸è¦ã«ãªã£ãŸãŸã‚å‰Šé™¤
from langchain_aws import ChatBedrock # Googleã‹ã‚‰AWS Bedrockç”¨ã«å¤‰æ›´
from langchain.memory import ConversationBufferMemory
from langchain_community.tools import DuckDuckGoSearchResults
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š (Bedrockç”¨ã«å¤‰æ›´) ---
DEFAULT_MODEL_NAME = "anthropic.claude-3-sonnet-20240229-v1:0"
AVAILABLE_MODELS = [
    "anthropic.claude-3-sonnet-20240229-v1:0", # Claude 3 Sonnet (ãƒãƒ©ãƒ³ã‚¹)
    "anthropic.claude-3-haiku-20240307-v1:0",   # Claude 3 Haiku (é«˜é€Ÿ)
    "anthropic.claude-3-opus-20240229-v1:0",    # Claude 3 Opus (é«˜æ€§èƒ½ãƒ»ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚ˆã£ã¦ã¯åˆ©ç”¨ä¸å¯)
    "cohere.command-r-plus-v1:0",              # Cohere Command R+
]
DEFAULT_TEMPERATURE = 0.0
DEFAULT_MAX_TOKENS = 2048
DEFAULT_USE_SEARCH = True

# --- LangChainã®ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ– ---

@st.cache_resource
def get_llm(model_name: str, temperature: float, max_tokens: int):
    """
    é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã€temperatureã€max_tokensã§LLM (Bedrock) ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
    """
    st.write(f"LLMã‚’åˆæœŸåŒ–ä¸­: model={model_name}, temp={temperature}, tokens={max_tokens}") # ãƒ‡ãƒãƒƒã‚°ç”¨
    try:
        # AWSèªè¨¼æƒ…å ±ã¯boto3ãŒç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•ã§èª­ã¿è¾¼ã‚€ãŸã‚ã€ã‚­ãƒ¼ã®ç›´æ¥æŒ‡å®šã¯ä¸è¦
        
        # AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
        aws_region = os.environ.get("AWS_REGION", "us-east-1")

        llm = ChatBedrock(
            # credentials_profile_name="your-profile-name", # ç‰¹å®šã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ã„ãŸã„å ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆè§£é™¤
            region_name=aws_region,
            model_id=model_name,
            model_kwargs={
                "temperature": temperature,
                # Claude 3, Cohere Command R+ ã¨ã‚‚ã« 'max_tokens' ã¨ã„ã†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å
                "max_tokens": max_tokens,
                # Claude 3ã®å ´åˆã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã“ã¡ã‚‰ã«æ¸¡ã™ã®ãŒã‚ˆã‚Šç¢ºå®Ÿ
                # "system": "ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            },
        )
        return llm
    except Exception as e:
        # èªè¨¼æƒ…å ±ãŒãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ†ã‹ã‚Šã‚„ã™ãã™ã‚‹
        if "NoCredentialsError" in str(e):
             st.error("AWSã®èªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ç’°å¢ƒå¤‰æ•° (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION) ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            st.error(f"LLM ({model_name}) ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.stop()

@st.cache_resource
def get_tools(use_search: bool):
    """
    åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚(ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—)
    use_searchãŒTrueã®å ´åˆã®ã¿DuckDuckGoæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’å«ã‚ã¾ã™ã€‚
    """
    st.write(f"ãƒ„ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–ä¸­: use_search={use_search}") # ãƒ‡ãƒãƒƒã‚°ç”¨
    if use_search:
        search_tool = DuckDuckGoSearchResults(name="duckduckgo_search_results", max_results=5)
        search_tool.description = "ç¾åœ¨ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚„ã€LLMã®çŸ¥è­˜ãŒåŠã°ãªã„ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ç­”ãˆã‚‹ãŸã‚ã«ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚’æ¤œç´¢ã—ã¾ã™ã€‚"
        return [search_tool]
    return []

@st.cache_resource
def get_agent_executor(_llm, _tools): # å¼•æ•°åã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆIDã§ã¯ãªãå†…å®¹ã«ä¾å­˜ã™ã‚‹ã‚ˆã†ã«ä¿ƒã™
    """
    LLMã¨ãƒ„ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦AgentExecutorã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚(ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—)
    """
    st.write("AgentExecutorã‚’åˆæœŸåŒ–ä¸­...") # ãƒ‡ãƒãƒƒã‚°ç”¨
    
    system_message_content = "ã‚ãªãŸã¯è¦ªåˆ‡ã§å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
    system_message_content += " ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯ã€å¿…ãšè¨€èªåã‚’æŒ‡å®šã—ãŸMarkdownã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆä¾‹: ```python ... ```ï¼‰ã§å›²ã£ã¦ãã ã•ã„ã€‚"
    if _tools: # ãƒ„ãƒ¼ãƒ«ãŒæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿æ¤œç´¢ã«é–¢ã™ã‚‹è¨€åŠã‚’è¿½åŠ 
        system_message_content += " å¿…è¦ã«å¿œã˜ã¦åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦æƒ…å ±ã‚’èª¿ã¹ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¤œç´¢çµæœã‚’åˆ©ç”¨ã—ãŸå ´åˆã¯ã€ãã®æƒ…å ±æºï¼ˆURLãªã©ï¼‰ã«ã¤ã„ã¦è§¦ã‚Œã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚"
    else:
        system_message_content += " ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ã€ã‚ãªãŸã®çŸ¥è­˜ã®ç¯„å›²ã§ç›´æ¥ç­”ãˆã¦ãã ã•ã„ã€‚"

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_message_content),
            MessagesPlaceholder(variable_name="chat_history", optional=True),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )
    agent = create_tool_calling_agent(_llm, _tools, prompt)
    
    agent_executor_instance = AgentExecutor(
        agent=agent,
        tools=_tools,
        verbose=True,
        handle_parsing_errors=True, 
        return_intermediate_steps=True
    )
    return agent_executor_instance

# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIã¨ãƒ­ã‚¸ãƒƒã‚¯ ---

st.set_page_config(page_title="Bedrock ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ£ãƒƒãƒˆ", layout="wide")
st.title("Bedrock ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ£ãƒƒãƒˆ ğŸ¤–ğŸ’¬ (AWS)")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã®è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    st.subheader("LLMè¨­å®š")
    selected_model = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        AVAILABLE_MODELS,
        index=AVAILABLE_MODELS.index(DEFAULT_MODEL_NAME)
    )
    current_temperature = st.slider(
        "Temperature", 0.0, 1.0, DEFAULT_TEMPERATURE, 0.05,
        help="å€¤ãŒä½ã„ã»ã©æ±ºå®šçš„ã§ä¸€è²«æ€§ã®ã‚ã‚‹å¿œç­”ã«ãªã‚Šã€é«˜ã„ã»ã©å¤šæ§˜ã§å‰µé€ çš„ãªå¿œç­”ã«ãªã‚Šã¾ã™ã€‚"
    )
    current_max_tokens = st.number_input(
        "Max Output Tokens", min_value=512, max_value=8192, value=DEFAULT_MAX_TOKENS, step=256,
        help="1å›ã®å¿œç­”ã§ç”Ÿæˆã•ã‚Œã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ€å¤§æ•°ã§ã™ã€‚"
    )

    st.subheader("ãƒ„ãƒ¼ãƒ«è¨­å®š")
    use_duckduckgo_search = st.toggle(
        "DuckDuckGoæ¤œç´¢ã‚’æœ‰åŠ¹ã«ã™ã‚‹", value=DEFAULT_USE_SEARCH,
        help="æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€AIã¯å¿…è¦ã«å¿œã˜ã¦Webæ¤œç´¢ã‚’è¡Œã„ã€æœ€æ–°æƒ…å ±ã«åŸºã¥ã„ã¦å›ç­”ã—ã¾ã™ã€‚"
    )
    
    st.markdown("---")
    if st.button("ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ", key="reset_chat_button"):
        st.session_state.messages = []
        st.session_state.search_url_history = []
        if "memory" in st.session_state:
            del st.session_state.memory
        get_llm.clear()
        get_tools.clear()
        get_agent_executor.clear()
        st.success("ä¼šè©±å±¥æ­´ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚")
        st.rerun()

# --- LLMã¨ãƒ„ãƒ¼ãƒ«ã®åˆæœŸåŒ– ---
llm = get_llm(selected_model, current_temperature, current_max_tokens)
tools = get_tools(use_duckduckgo_search)
agent_executor = get_agent_executor(llm, tools)

st.caption(f"Model: {selected_model} | Temp: {current_temperature} | MaxTokens: {current_max_tokens} | Search: {'ON' if use_duckduckgo_search else 'OFF'}")


# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¨ãƒ¡ãƒ¢ãƒªã®ç®¡ç† ---
# (ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯å¤‰æ›´ãªã—)
if "messages" not in st.session_state:
    st.session_state.messages = []
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
if "search_url_history" not in st.session_state:
    st.session_state.search_url_history = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    st.session_state.messages.append({"role": "user", "content": user_prompt})
    with st.chat_message("user"):
        st.markdown(user_prompt)

    with st.chat_message("assistant"):
        try:
            with st.spinner("AIãŒè€ƒãˆã¦ã„ã¾ã™..."):
                chat_history_messages = st.session_state.memory.chat_memory.messages
                
                response_data = agent_executor.invoke(
                    {
                        "input": user_prompt,
                        "chat_history": chat_history_messages
                    }
                )
                ai_response = response_data.get('output', "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                intermediate_steps = response_data.get('intermediate_steps', [])

                # --- URLæŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯ (å¤‰æ›´ãªã—ã€ãŸã ã—æ­£è¦è¡¨ç¾ã‚’å°‘ã—æ”¹å–„) ---
                urls_found_this_turn = []
                if intermediate_steps:
                    for step in intermediate_steps:
                        action, observation = step
                        if action.tool == "duckduckgo_search_results": 
                            if isinstance(observation, str):
                                # 'link:' ã ã‘ã§ãªã 'url:' ãªã©ã«ã‚‚å¯¾å¿œã§ãã‚‹ã‚ˆã†æŸ”è»Ÿã«
                                found_links = re.findall(r"\[source\]:\s*(https?://[^\s)]+)", observation, re.IGNORECASE)
                                if not found_links:
                                     # DuckDuckGoSearchResultsã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‡ºåŠ›å½¢å¼ã‹ã‚‰URLã‚’æŠ½å‡º
                                     found_links = re.findall(r"link:\s*(https?://[^\s]+)", observation, re.IGNORECASE)
                                
                                urls_found_this_turn.extend(found_links)
                                
                for url in urls_found_this_turn:
                    if url not in st.session_state.search_url_history:
                        st.session_state.search_url_history.append(url)

            st.markdown(ai_response)
            
            with st.expander("Markdownã‚½ãƒ¼ã‚¹ã‚’ã‚³ãƒ”ãƒ¼"):
                st.code(ai_response, language='markdown')
                
            st.session_state.messages.append({"role": "assistant", "content": ai_response})
            st.session_state.memory.save_context({"input": user_prompt}, {"output": ai_response})

        except Exception as e:
            error_message = f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            st.error(error_message)
            st.session_state.messages.append({"role": "assistant", "content": error_message})


# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ä¸‹éƒ¨ (URLå±¥æ­´ & APIã‚­ãƒ¼èª¬æ˜ã‚’Bedrockç”¨ã«å¤‰æ›´) ---
with st.sidebar:
    st.markdown("---")
    st.subheader("ğŸŒ å‚ç…§ã•ã‚ŒãŸURLå±¥æ­´")
    if st.session_state.get("search_url_history"):
        for i, url in enumerate(reversed(st.session_state.search_url_history)):
            try:
                domain = url.split('//')[-1].split('/')[0]
            except:
                domain = "ä¸æ˜ãªãƒ‰ãƒ¡ã‚¤ãƒ³"
            st.markdown(f"{len(st.session_state.search_url_history) - i}. [{domain}]({url})")
    else:
        st.caption("ã¾ã æ¤œç´¢ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    st.markdown("---")
    st.subheader("èªè¨¼ã«ã¤ã„ã¦")
    st.caption("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å®Ÿè¡Œç’°å¢ƒã«è¨­å®šã•ã‚ŒãŸAWSèªè¨¼æƒ…å ±ï¼ˆç’°å¢ƒå¤‰æ•°ãªã©ï¼‰ã‚’ä½¿ç”¨ã—ã¦AWS Bedrockã«æ¥ç¶šã—ã¾ã™ã€‚")
    st.markdown("""
    **è¨­å®šæ–¹æ³•:**
    1. AWS IAMã§ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚
    2. ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚
       - `AWS_ACCESS_KEY_ID`
       - `AWS_SECRET_ACCESS_KEY`
       - `AWS_REGION` (ä¾‹: `us-east-1`)
    
    [AWSãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: èªè¨¼æƒ…å ±ã®è¨­å®š](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)
    """)

    st.markdown("---")
    st.subheader("ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
    if st.checkbox("ä¼šè©±ãƒ¡ãƒ¢ãƒªã‚’è¡¨ç¤º (LangChain)"):
        if "memory" in st.session_state and hasattr(st.session_state.memory, "chat_memory"):
            st.write(st.session_state.memory.chat_memory.messages)
        else:
            st.caption("ãƒ¡ãƒ¢ãƒªã¯ã¾ã åˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")