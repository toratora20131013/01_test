{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceddc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import traceback # エラー発生時の詳細情報表示用\n",
    "\n",
    "print(f\"h5py version: {h5py.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ebdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 設定 ---\n",
    "FILE_NAME = \"processdata.h5\"\n",
    "\n",
    "# --- ローカルファイルの存在確認 ---\n",
    "if not os.path.exists(FILE_NAME):\n",
    "    print(f\"エラー: HDF5ファイル '{FILE_NAME}' が見つかりません。\")\n",
    "    print(f\"このNotebookと同じディレクトリに '{FILE_NAME}' を配置してください。\")\n",
    "    # Jupyter Notebookでは処理をここで止めるために例外を発生させます\n",
    "    raise FileNotFoundError(f\"HDF5 file '{FILE_NAME}' not found. Please place it in the same directory as this notebook.\")\n",
    "else:\n",
    "    print(f\"ローカルHDF5ファイルを使用します: '{FILE_NAME}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hdf5_structure(item, indent_level=0):\n",
    "    \"\"\"HDF5ファイルまたはグループ内の構造を再帰的に表示する関数\"\"\"\n",
    "    indent = '  ' * indent_level  # インデントの深さを調整\n",
    "    if isinstance(item, h5py.File) or isinstance(item, h5py.Group):\n",
    "        for key in item.keys():\n",
    "            sub_item = item[key]\n",
    "            print(f\"{indent}├── {key}  (Type: {type(sub_item).__name__})\")\n",
    "            if isinstance(sub_item, h5py.Group):\n",
    "                print_hdf5_structure(sub_item, indent_level + 1)\n",
    "            elif isinstance(sub_item, h5py.Dataset):\n",
    "                print(f\"{indent}│   └── Shape: {sub_item.shape}, Dtype: {sub_item.dtype}\")\n",
    "                # データセットの属性も表示（もしあれば）\n",
    "                if sub_item.attrs:\n",
    "                    print(f\"{indent}│       └── Attributes:\")\n",
    "                    for attr_name, attr_val in sub_item.attrs.items():\n",
    "                        attr_val_str = str(attr_val)\n",
    "                        # 属性値が長すぎる場合は省略\n",
    "                        display_attr_val = attr_val_str[:70] + '...' if len(attr_val_str) > 70 else attr_val_str\n",
    "                        print(f\"{indent}│           ├── {attr_name}: {display_attr_val}\")\n",
    "    else:\n",
    "        print(f\"{indent}Error: Expected h5py.File or h5py.Group, got {type(item)}\")\n",
    "\n",
    "\n",
    "print(f\"\\n--- HDF5ファイル '{FILE_NAME}' の構造 ---\")\n",
    "try:\n",
    "    with h5py.File(FILE_NAME, 'r') as hf: # 'r'モードで読み込み専用で開く\n",
    "        print(f\"{FILE_NAME} (File)\")\n",
    "        print_hdf5_structure(hf, indent_level=0)\n",
    "except Exception as e:\n",
    "    print(f\"HDF5ファイルの読み込みまたは構造表示中にエラーが発生しました: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62be2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "# 例: 確認したいデータセットのパスを指定します。\n",
    "# 上記の「HDF5ファイル の構造」の出力を参考に、実際のパスに書き換えてください。\n",
    "# 例1: dataset_path_to_inspect = 'RESULTS/Zone1/fluid/vx' (Fluentからのエクスポートの典型例 - 推測)\n",
    "# 例2: dataset_path_to_inspect = 'Coordinates/X_Coordinates' (別の例)\n",
    "dataset_path_to_inspect = 'vertex/x' # 必ず書き換えてください！\n",
    "# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "\n",
    "\n",
    "print(f\"\\n--- データセット '{dataset_path_to_inspect}' の内容確認 ---\")\n",
    "if dataset_path_to_inspect == 'PLEASE_REPLACE_WITH_ACTUAL_DATASET_PATH':\n",
    "    print(\"警告: `dataset_path_to_inspect` が書き換えられていません。\")\n",
    "    print(\"上記のファイル構造を確認し、有効なデータセットパスを指定してください。\")\n",
    "else:\n",
    "    try:\n",
    "        with h5py.File(FILE_NAME, 'r') as hf:\n",
    "            if dataset_path_to_inspect in hf:\n",
    "                dataset = hf[dataset_path_to_inspect]\n",
    "                print(f\"データセット名 (フルパス): {dataset.name}\")\n",
    "                print(f\"形状 (Shape): {dataset.shape}\")\n",
    "                print(f\"データ型 (Dtype): {dataset.dtype}\")\n",
    "                print(f\"総要素数: {dataset.size}\")\n",
    "\n",
    "                # データセットの属性を表示 (もしあれば)\n",
    "                if dataset.attrs:\n",
    "                    print(\"属性 (Attributes):\")\n",
    "                    for attr_name, attr_val in dataset.attrs.items():\n",
    "                        attr_val_str = str(attr_val)\n",
    "                        display_attr_val = attr_val_str[:70] + '...' if len(attr_val_str) > 70 else attr_val_str\n",
    "                        print(f\"  - {attr_name}: {display_attr_val}\")\n",
    "                \n",
    "                # データの一部を表示 (データが非常に大きい場合は注意が必要です)\n",
    "                num_preview_elements = 5 # 各次元でプレビューする要素の数を制限\n",
    "                print(\"\\nデータプレビュー:\")\n",
    "                if dataset.ndim == 0: # スカラーデータセット\n",
    "                     print(f\"  値: {dataset[()]}\") # スカラー値の取得\n",
    "                elif dataset.size == 0: # 空のデータセット\n",
    "                    print(\"  データセットは空です。\")\n",
    "                else: # 1次元以上の配列\n",
    "                    # 各次元の最初の数要素を表示するスライスを作成\n",
    "                    slicing = []\n",
    "                    actual_elements_shown = []\n",
    "                    for dim_size in dataset.shape:\n",
    "                        preview_count = min(num_preview_elements, dim_size)\n",
    "                        slicing.append(slice(0, preview_count))\n",
    "                        actual_elements_shown.append(preview_count)\n",
    "                    \n",
    "                    preview_data = dataset[tuple(slicing)]\n",
    "                    print(f\"  最初の約 {actual_elements_shown} 要素 (またはそれ以下) を表示:\")\n",
    "                    print(preview_data)\n",
    "\n",
    "                    # (オプション) もしデータが数値型なら、基本的な統計情報を表示\n",
    "                    # 注意: 全データをメモリにロードするため、巨大なデータセットでは問題が起きる可能性があります。\n",
    "                    # 必要に応じてコメントを解除し、データサイズを考慮して使用してください。\n",
    "                    # if np.issubdtype(dataset.dtype, np.number) and dataset.size > 0 and dataset.size < 1_000_000: # 例: 100万要素未満の場合のみ\n",
    "                    #     print(\"\\n基本的な統計情報 (全データから計算):\")\n",
    "                    #     try:\n",
    "                    #         full_data = dataset[:] # 全データをロード\n",
    "                    #         print(f\"  最小値: {np.min(full_data)}\")\n",
    "                    #         print(f\"  最大値: {np.max(full_data)}\")\n",
    "                    #         print(f\"  平均値: {np.mean(full_data)}\")\n",
    "                    #         print(f\"  標準偏差: {np.std(full_data)}\")\n",
    "                    #     except Exception as stat_e:\n",
    "                    #         print(f\"  統計情報の計算中にエラー: {stat_e}\")\n",
    "            else:\n",
    "                print(f\"エラー: データセット '{dataset_path_to_inspect}' がファイル内に見つかりません。\")\n",
    "                print(\"上記のファイル構造を確認し、正しいパスを指定してください。\")\n",
    "                print(\"利用可能なトップレベルのオブジェクト:\", list(hf.keys()))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"データセット '{dataset_path_to_inspect}' の読み込みまたは表示中にエラーが発生しました: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c878a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "# --- (前のセルで h5py, numpy, pyvista as pv, os, traceback がインポート済みと仮定) ---\n",
    "# --- (FILE_NAME = \"processdata.h5\" も定義済みと仮定) ---\n",
    "\n",
    "print(\"\\n--- ステップX: HDF5データからPyVista UnstructuredGridを構築して可視化 ---\")\n",
    "\n",
    "try:\n",
    "    with h5py.File(FILE_NAME, 'r') as hf:\n",
    "        # 1. 節点座標の読み込みと整形\n",
    "        print(\"節点座標を読み込み中...\")\n",
    "        if 'vertex/x' in hf and 'vertex/y' in hf and 'vertex/z' in hf:\n",
    "            x_coords = hf['vertex/x'][:].squeeze() # .squeeze()で次元1の軸を削除 (1, N) -> (N,)\n",
    "            y_coords = hf['vertex/y'][:].squeeze()\n",
    "            z_coords = hf['vertex/z'][:].squeeze()\n",
    "\n",
    "            # (N, 3) の形状のNumPy配列に結合\n",
    "            points = np.vstack((x_coords, y_coords, z_coords)).T\n",
    "            print(f\"  読み込んだ節点数: {points.shape[0]}, 次元: {points.shape[1]}\")\n",
    "            if points.shape[0] != 18905 or points.shape[1] != 3:\n",
    "                print(f\"    警告: 期待される節点形状 (18905, 3) と異なります: {points.shape}\")\n",
    "        else:\n",
    "            raise KeyError(\"必要な座標データセット (vertex/x, vertex/y, vertex/z) が見つかりません。\")\n",
    "\n",
    "        # 2. 要素の接続情報の読み込みと整形\n",
    "        print(\"\\n要素の接続情報を読み込み中...\")\n",
    "        if 'elements' in hf:\n",
    "            # elementsデータセットは (4, 87007) の形状で、各列が1つの要素を表していると仮定\n",
    "            # PyVista/VTKは各行が1つの要素を表す形式 (num_elements, num_nodes_per_element) を好むので転置(.T)\n",
    "            elements_raw = hf['elements'][:].T # (87007, 4) になるはず\n",
    "            print(f\"  読み込んだ要素の形状 (転置後): {elements_raw.shape}\")\n",
    "\n",
    "            # データ型を整数に変換 (節点インデックスのため)\n",
    "            # また、MATLAB由来の場合、インデックスが1から始まる可能性があるので、0から始まるように調整\n",
    "            # ここではまず整数に変換し、インデックスの範囲を確認してから調整を検討\n",
    "            elements_int = elements_raw.astype(np.int_) # または np.int64\n",
    "\n",
    "            # 節点インデックスが0から始まるか、1から始まるかを確認 (データの最小値で判断)\n",
    "            min_index = np.min(elements_int)\n",
    "            if min_index == 1:\n",
    "                print(\"  要素の節点インデックスが1から始まっていると判断し、0から始まるように調整します。\")\n",
    "                elements_int -= 1\n",
    "            elif min_index < 0:\n",
    "                print(f\"  警告: 要素の節点インデックスに負の値 ({min_index}) が含まれています。データを確認してください。\")\n",
    "            else:\n",
    "                print(\"  要素の節点インデックスは既に0から始まっているか、0以上のようです。\")\n",
    "\n",
    "\n",
    "            # PyVistaのUnstructuredGridに入力するセル配列形式を作成\n",
    "            # 四面体 (tetra) の場合、各セルの前に節点数 (4) を挿入\n",
    "            # VTK_TETRA のセルタイプIDは 10\n",
    "            num_elements = elements_int.shape[0]\n",
    "            # [4, n0,n1,n2,n3,  4, n4,n5,n6,n7, ...] という1D配列を作る\n",
    "            cells_pv = np.hstack((np.full((num_elements, 1), 4, dtype=np.int_), elements_int)).flatten()\n",
    "            cell_types_pv = np.full(num_elements, pv.CellType.TETRA.value, dtype=np.uint8)\n",
    "            \n",
    "            print(f\"  PyVista用のセル配列の長さ: {len(cells_pv)}\")\n",
    "            print(f\"  PyVista用のセルタイプ配列の長さ: {len(cell_types_pv)}\")\n",
    "        else:\n",
    "            raise KeyError(\"必要な要素データセット ('elements') が見つかりません。\")\n",
    "\n",
    "        # 3. PyVista UnstructuredGridの作成\n",
    "        print(\"\\nPyVista UnstructuredGrid を作成中...\")\n",
    "        grid = pv.UnstructuredGrid(cells_pv, cell_types_pv, points)\n",
    "        print(\"UnstructuredGrid の作成成功。\")\n",
    "        print(grid) # gridオブジェクトの情報を表示\n",
    "\n",
    "        # 4. (オプション) スカラーデータの付加 (例: doping)\n",
    "        if 'doping' in hf:\n",
    "            print(\"\\n'doping' データを節点データとして付加中...\")\n",
    "            doping_data = hf['doping'][:].squeeze()\n",
    "            if doping_data.shape[0] == grid.n_points:\n",
    "                grid.point_data['doping'] = doping_data\n",
    "                print(f\"  'doping' データを {grid.n_points} 個の節点に付加しました。\")\n",
    "            else:\n",
    "                print(f\"  警告: 'doping' データの要素数 ({doping_data.shape[0]}) が節点数 ({grid.n_points}) と一致しません。付加をスキップします。\")\n",
    "        \n",
    "        # 5. PyVistaでの可視化\n",
    "        print(\"\\nPyVistaで3Dメッシュを可視化中...\")\n",
    "        plotter = pv.Plotter(notebook=True, window_size=[800,600]) # Jupyterバックエンドは前のセルで設定済みと仮定\n",
    "        \n",
    "        # 'doping' データがあれば、それで色付けして表示\n",
    "        if 'doping' in grid.point_data:\n",
    "            plotter.add_mesh(grid, scalars='doping', show_edges=True, cmap='viridis')\n",
    "            plotter.add_scalar_bar(title='Doping Concentration')\n",
    "        else:\n",
    "            plotter.add_mesh(grid, show_edges=True, color='lightblue')\n",
    "            \n",
    "        plotter.view_isometric()\n",
    "        plotter.enable_zoom_style() # enable_zoom_scaling() から修正\n",
    "        plotter.show_axes()\n",
    "        plotter.add_title(\"3D Mesh from HDF5 (processdata.h5)\")\n",
    "        plotter.show()\n",
    "\n",
    "except KeyError as ke:\n",
    "    print(f\"キーエラー: HDF5ファイル内に期待されるデータセットが見つかりませんでした: {ke}\")\n",
    "    print(\"ファイル構造を再確認してください。\")\n",
    "except Exception as e:\n",
    "    print(f\"メッシュの構築または可視化中にエラーが発生しました: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b22167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
